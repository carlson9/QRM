---
title: "Day 7 - deviance"
author: "David Carlson"
date: "March 21, 2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
setwd('~/QRM/inclass/day7deviance/')
```

# Newton-Raphson

Basically, all you need to know is $f(x_1)=f(x_0)+(x_1-x_0)f'(x_0)+\frac{1}{2!}(x_1-x_0)^2f''(x_0)+\frac{1}{3!}(x_1-x_0)^3f'''(x_0)+\ldots,$, which intuitively is similar to $f(x_1)\approx f(x_0)+(x_1-x_0)f'(x_0) \approx f(x_0) + \Delta x \times \frac{\Delta y}{\Delta x}$. We use this to find roots.

# Weighted Least Squares

Corrects for heteroskedasticity, but does not allow for covariation. We will go over this when we get to Bayesian. It is almost never the best solution.

# Iterative Weighted Least Squares

We want to maximize the likelihood, and minimize the loss. Algorithm:

* Assign starting values to the weights, generally equal to one
* Estimate beta using weighted least squares with the current weights
* Update the weights using the new estimated mean vector
* Repeat Steps 2 and 3 until convergence

# Profile Likelihood Confidence Intervals

Wald-type intervals with upper and lower bounds computed in the following way:

$[LB,UB]=\hat{\beta}_{k} \pm z_{1-\frac{\alpha}{2}}\times \sqrt{VC_{k,k}}$

We can (should) use the $t$-distribution for moderate sample sizes.

LRT: $2[\ell(\hat{\theta}, \hat{\psi})-\ell(\theta_0)] \sim \chi^2(1)$



